{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvA7XjfNLyhx"
   },
   "source": [
    "This notebook evaluates the learning fair representations algorithm on COMPAS data\n",
    "https://proceedings.mlr.press/v28/zemel13.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3v9wGJN8kIQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSDsZVOpc7f1"
   },
   "outputs": [],
   "source": [
    "#features selected as per this tutorial: https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb\n",
    "df = pd.read_csv('COMPAS_preprocessed.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "col_X = ['race','age', 'c_charge_degree', 'score_text', 'sex',\n",
    "       'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid', \n",
    "        'days_in_jail']\n",
    "X = df[col_X]\n",
    "y = df['two_year_recid']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_pos = X_train[X_train['race']==1]\n",
    "X_neg = X_train[X_train['race']==0]\n",
    "\n",
    "y_pos = np.array(y_train[X_train['race']==1])\n",
    "y_neg = np.array(y_train[X_train['race']==0])\n",
    "\n",
    "col_X = ['age', 'c_charge_degree', 'score_text', 'sex',\n",
    "       'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid', \n",
    "        'days_in_jail']\n",
    "\n",
    "X_pos = np.array(X_pos[col_X])\n",
    "X_neg = np.array(X_neg[col_X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52-qrc-GMBbz"
   },
   "source": [
    "We've imported our dataset, and we only select the columns we need, as well as our target variable: two_year_recid Feature seelction is based on this notebook: https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYULwq3M0dR4"
   },
   "outputs": [],
   "source": [
    "# Equation 12\n",
    "\n",
    "def distances(X, v, alpha, N, D, K):\n",
    "    dists = np.zeros((N, D))\n",
    "    for n in range(N):\n",
    "        for i in range(D):\n",
    "            for k in range(K):\n",
    "              #print('n i k: ', n, i,k)\n",
    "              dists[n, k] += (X[n, i] - v[k, i]) * (X[n, i] - v[k, i]) * alpha[i]\n",
    "    return dists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1RspnYL0gQa"
   },
   "outputs": [],
   "source": [
    "# Equation 2&3\n",
    "def M_nk(dists, N, K):\n",
    "    M_nk = np.zeros((N, K))\n",
    "    exp = np.zeros((N, K))\n",
    "    denom = np.zeros(N)\n",
    "    for n in range(N):\n",
    "        for j in range(K):\n",
    "            exp[n, j] = np.exp(-1 * dists[n, j])\n",
    "            denom[n] += exp[n, j]\n",
    "        for j in range(K):\n",
    "            if denom[n]:\n",
    "                M_nk[n, j] = exp[n, j] / denom[n]\n",
    "            else:\n",
    "                M_nk[n, j] = exp[n, j] / 1e-6\n",
    "    return M_nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxsMnkMq0gr6"
   },
   "outputs": [],
   "source": [
    "# Equation 6\n",
    "def M_k(M_nk, N, K):\n",
    "    M_k = np.zeros(K)\n",
    "    for j in range(K):\n",
    "        for n in range(N):\n",
    "            M_k[j] += M_nk[n, j]\n",
    "        M_k[j] /= N\n",
    "    return M_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFde1E6F0oua"
   },
   "outputs": [],
   "source": [
    "# Equation 8&9\n",
    "def Loss_x(X, M_nk, v, N, D, K):\n",
    "    x_n_hat = np.zeros((N, D))\n",
    "    L_x = 0.0\n",
    "    for n in range(N):\n",
    "        for i in range(D):\n",
    "            for k in range(K):\n",
    "                x_n_hat[n, i] += M_nk[n, k] * v[k, i]\n",
    "            L_x += (X[n, i] - x_n_hat[n, i]) * (X[n, i] - x_n_hat[n, i])\n",
    "    return x_n_hat, L_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stQI3c6N0qok"
   },
   "outputs": [],
   "source": [
    "# Equation 10&11\n",
    "def Loss_y(M_nk, y, w, N, K):\n",
    "    yhat = np.zeros(N)\n",
    "    L_y = 0.0\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            yhat[n] += M_nk[n, k] * w[k]\n",
    "        yhat[n] = 1e-6 if yhat[n] <= 0 else yhat[n]\n",
    "        yhat[n] = 0.999 if yhat[n] >= 1 else yhat[n]\n",
    "        L_y += -1 * y[n] * np.log(yhat[n]) - (1.0 - y[n]) * np.log(1.0 - yhat[n])\n",
    "    return yhat, L_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAz9I0br0sQV"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Equation 4 (target function)\n",
    "def LFR(params, X_pos, X_neg, y_pos, y_neg, K, A_z, A_x, A_y, results=0):   \n",
    "    #LFR.iters += 1\n",
    "    N_pos, D = X_pos.shape # protected set\n",
    "    N_neg, _ = X_neg.shape # non-protected set\n",
    "    \n",
    "    #print('PARAMS SHAPE: ', params.shape)\n",
    "    alpha_pos = params[:D]\n",
    "    alpha_neg = params[D: 2 * D]\n",
    "    w = params[2 * D: (2 * D) + K]\n",
    "    #print(alpha_pos.shape, alpha_neg.shape, w.shape)\n",
    "    v = np.matrix(params[(2 * D) + K:]).reshape((K, D)) # set of prototypes\n",
    "\n",
    "    dists_pos = distances(X_pos, v, alpha_pos, N_pos, D, K)\n",
    "    dists_neg = distances(X_neg, v, alpha_neg, N_neg, D, K)\n",
    "\n",
    "    M_nk_pos = M_nk(dists_pos, N_pos, K)\n",
    "    M_nk_neg = M_nk(dists_neg, N_neg, K)\n",
    "\n",
    "    M_k_pos = M_k(M_nk_pos, N_pos, K)\n",
    "    M_k_neg = M_k(M_nk_neg, N_neg, K)\n",
    "\n",
    "    L_z = 0.0\n",
    "    for k in range(K):\n",
    "        L_z += abs(M_k_pos[k] - M_k_neg[k]) # Equation 7\n",
    "\n",
    "    x_n_hat_pos, L_x_pos = Loss_x(X_pos, M_nk_pos, v, N_pos, D, K)\n",
    "    x_n_hat_neg, L_x_neg = Loss_x(X_neg, M_nk_neg, v, N_neg, D, K)\n",
    "    L_x = L_x_pos + L_x_neg\n",
    "\n",
    "    yhat_pos, L_y_pos = Loss_y(M_nk_pos, y_pos, w, N_pos, K)\n",
    "    yhat_neg, L_y_neg = Loss_y(M_nk_neg, y_neg, w, N_neg, K)\n",
    "    L_y = L_y_pos + L_y_neg\n",
    "\n",
    "    criterion = A_x * L_x + A_y * L_y + A_z * L_z\n",
    "\n",
    "    if results != 0:\n",
    "        return yhat_pos, yhat_neg, M_nk_pos, M_nk_neg\n",
    "    else:\n",
    "        return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypR27zHWMHoV"
   },
   "source": [
    "We use scikit learn's framework for optimization: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize https://scipy-lectures.org/advanced/mathematical_optimization/auto_examples/plot_non_bounds_constraints.html\n",
    "\n",
    "Each of the constraints required for the framework to work needs to be programmed s.t. >= 0 for it to be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggSq_RYrZNlu",
    "outputId": "4f934ef2-4d27-409c-ae1e-36c336512341"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "from numpy import linalg as LA\n",
    "D = X_pos.shape[1]\n",
    "K = 5\n",
    "alpha_pos = np.random.uniform(size=D)\n",
    "alpha_neg = np.random.uniform(size=D)\n",
    "w = np.random.uniform(size=K) \n",
    "v = np.random.uniform(size=K*D)\n",
    "params = alpha_pos\n",
    "for item in [alpha_neg, w, v]:\n",
    "  params = np.append(params, item.flatten())\n",
    "res = scipy.optimize.minimize(LFR, \n",
    "                        x0=params, \n",
    "                        args=(X_pos, X_neg, y_pos, y_neg, K, 1000, 1e-4, 0.1),\n",
    "                        method='SLSQP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wtd036BTuenf"
   },
   "outputs": [],
   "source": [
    "params = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AuZ7J0QrAa3l"
   },
   "outputs": [],
   "source": [
    "params = [ 5.82069852e-01,  5.02124425e-01,  9.10965658e-01,  2.74610268e-01,\n",
    "        3.97474821e-01,  8.59815622e-01, -1.23429220e-02,  8.01572071e-01,\n",
    "        6.20959318e-01,  4.11713157e-01,  1.12769911e-01,  6.35033690e-01,\n",
    "        4.74356319e-01,  3.19261536e-01,  5.02481813e-01,  9.02021525e-01,\n",
    "        5.20529878e-01,  2.21460812e-01,  4.10512509e-02,  1.48162758e-01,\n",
    "        7.60217917e-01,  5.16203490e-01,  2.11645900e-01,  1.22500502e-03,\n",
    "        8.55725789e-01,  8.68243998e-01,  5.47817586e-01,  9.90537625e-01,\n",
    "        3.74669836e-01,  2.39921902e-01,  5.35120539e-01,  5.56152285e-01,\n",
    "        9.91920355e-01,  2.24086371e-01,  5.26454612e-01,  3.54774321e-01,\n",
    "        1.68337243e-01, -2.53014775e-01,  5.95022381e-01,  4.20818566e-02,\n",
    "        8.83086285e-01,  5.02413549e-01,  9.78994332e-01,  1.46986557e-01,\n",
    "        8.49847517e-01,  5.99330128e-01,  2.27207712e-01,  9.78283710e-01,\n",
    "        5.06313056e-02,  1.25743358e-02,  3.29875819e+00,  7.98292772e-01,\n",
    "        6.04982755e-01,  5.08084165e-01,  4.49117642e-01,  5.38505770e-01,\n",
    "        1.35323396e+00,  2.13704460e-01,  3.18681907e-01,  7.39004365e-01,\n",
    "        5.14488530e-01,  1.35828801e-01,  4.25325165e-01,  1.88144890e-01,\n",
    "        3.54994983e-01,  3.04144632e-01,  6.37803973e-01,  3.28983126e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RO_WgyU7yREz"
   },
   "outputs": [],
   "source": [
    "D = X_pos.shape[1]\n",
    "K = 5\n",
    "alpha_pos = params[:D]\n",
    "alpha_neg = params[D: 2*D]\n",
    "w = params[2*D: (2*D) + K]\n",
    "v = np.array(params[(2*D) + K: ]).reshape((K,D))#np.random.uniform(size=K*D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n54b3StO5Etb"
   },
   "source": [
    "Now we evaluate this algorithm based on the 4 metrics: parity, odd equality, accuracy, and calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yq6bd6Ezui_r",
    "outputId": "4cf2ba13-5765-441c-a850-8ce7986a941c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.584070796460177, 0.6409774436090225)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##calculate parity P(Y_hat = 1 | S = 0) = P(Y_hat = 1 | S = 1)\n",
    "\n",
    "#1) segment test dataset into sensitive and non sensitive\n",
    "X_pos = X_test[X_test['race']==1]\n",
    "X_neg = X_test[X_test['race']==0]\n",
    "\n",
    "y_pos = np.array(y_test[X_test['race']==1])\n",
    "y_neg = np.array(y_test[X_test['race']==0])\n",
    "\n",
    "col_X = ['age', 'c_charge_degree', 'score_text', 'sex',\n",
    "       'priors_count', 'days_b_screening_arrest', \n",
    "       'decile_score', 'days_in_jail', 'is_recid']\n",
    "\n",
    "X_pos = np.array(X_pos[col_X])\n",
    "X_neg = np.array(X_neg[col_X])\n",
    "\n",
    "#2) calculate Y_hat for neg & pos\n",
    "#recover M_nk\n",
    "N_pos, D = X_pos.shape # protected set\n",
    "N_neg, _ = X_neg.shape # non-protected set\n",
    "\n",
    "\n",
    "dists_pos = distances(X_pos, v, alpha_pos, N_pos, D, K)\n",
    "dists_neg = distances(X_neg, v, alpha_neg, N_neg, D, K)\n",
    "\n",
    "M_nk_pos = M_nk(dists_pos, N_pos, K)\n",
    "M_nk_neg = M_nk(dists_neg, N_neg, K)\n",
    "\n",
    "yhat_pos, lypos = Loss_y(M_nk_pos, y_pos, w, N_pos, K)\n",
    "yhat_neg, lyneg = Loss_y(M_nk_neg, y_neg, w, N_neg, K)\n",
    "\n",
    "#3) find y_hat = 1 for both neg and positive\n",
    "\"\"\"FINDING PARITY\"\"\"\n",
    "(len(yhat_neg[yhat_neg > 0.5])/len(yhat_neg), #for non-sensitive attribute #0.584070796460177\n",
    "  len(yhat_pos[yhat_pos > 0.5])/len(yhat_pos)) #for sensitive attribute #0.6409774436090225"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRFrvp_2PqT7"
   },
   "source": [
    "#parity (eval #1)\n",
    "P(Yhat = 1 | sensitive attribute = 1) = 64.1%\n",
    "P(Yhat = 1 | sensitive attribute = 0) = 58.4%\n",
    "The algorithm is able to more accurately predict the protected group as y = 1 than the non protected group, meaning it is more likely to identify them as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWAtxKbY1xsl",
    "outputId": "876c224f-bb97-4217-9bf1-765dad8fe886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6495412844036698 0.6319845857418112\n",
      "0.6535433070866141 0.5424528301886793\n"
     ]
    }
   ],
   "source": [
    "##evaluation metric 2: equality of odds\n",
    "\"\"\"EQUALITY OF ODDS\"\"\"\n",
    "\n",
    "odds_pos = yhat_pos\n",
    "odds_neg = yhat_neg\n",
    "#protected: y = 1, then y =0 \n",
    "print(len(y_pos[(odds_pos > 0.5) & (y_pos > 0.5)]) / len(y_pos[y_pos > 0.5]), len(y_pos[(odds_pos > 0.5) & (y_pos <= 0.5)]) / len(y_pos[y_pos <= 0.5]))\n",
    "#nonprotected: y = 1, then y =0 \n",
    "print(len(y_neg[(odds_neg > 0.5) & (y_neg > 0.5)]) / len(y_neg[y_neg > 0.5]), len(y_neg[(odds_neg > 0.5) & (y_neg <= 0.5)]) / len(y_neg[y_neg <= 0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYGXJVy5P-wo"
   },
   "source": [
    "equality of odds (eval #2)\n",
    "For when true value of y = 0 the model predicts the sensitive group as y =1 63.2% of the time, and 54.2% accurately for the non-protected group\n",
    "\n",
    "For when y = 1, the model predicts the sensitive group as y=1 65% of the time, and 65% accurately for the non-protected group\n",
    "\n",
    "Given this information, we can see that the algorithm is more likely to predict the sensitive group as y =1 even when they are not indeed rescinded. It's also interesting to see that it predicts the sensitive group around the same likelihood regardless of their status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Oub8UGv38sV",
    "outputId": "378fc875-652a-4651-d2c6-bc3159bf1653"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5195177956371986"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"evaluation metric 3: accuracy\"\"\"\n",
    "yhat_pos1 = yhat_pos\n",
    "yhat_pos1[yhat_pos1 > 0.5] = 1\n",
    "yhat_pos1[yhat_pos1 <= 0.5] = 0\n",
    "\n",
    "yhat_neg1 = yhat_neg\n",
    "yhat_neg1[yhat_neg1 > 0.5] = 1\n",
    "yhat_neg1[yhat_neg1 <= 0.5] = 0\n",
    "(len(yhat_pos1[(yhat_pos1==y_pos)]) + \n",
    " len(yhat_neg1[(yhat_neg1 == y_neg)])) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q48rATDXBvYv"
   },
   "source": [
    "# eval metric 3: accuracy\n",
    "The overall accuracy of the model is 52%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYmbGXAcw8XI",
    "outputId": "ae1fb7cb-e575-4a72-84ea-539c060d2f9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40.,  1., -1., ..., -1.,  3.,  0.],\n",
       "       [23.,  0.,  0., ..., -1.,  7.,  0.],\n",
       "       [29.,  0., -1., ..., -1.,  2.,  1.],\n",
       "       ...,\n",
       "       [61.,  1., -1., ..., -4.,  1.,  0.],\n",
       "       [48.,  0., -1., ..., -1.,  1.,  1.],\n",
       "       [27.,  0., -1., ..., -1.,  3.,  0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cols=['race', 'age', 'c_charge_degree',\t'score_text',\t'sex'\t,'priors_count',\n",
    " #      'days_b_screening_arrest',\t'decile_score',\t'days_in_jail']\n",
    "X_pos = X_test[X_test['race']==1]\n",
    "X_neg = X_test[X_test['race']==0]\n",
    "\n",
    "y_pos = np.array(y_test[X_test['race']==1])\n",
    "y_neg = np.array(y_test[X_test['race']==0])\n",
    "\n",
    "col_X = ['race', 'age', 'c_charge_degree', 'score_text', 'sex',\n",
    "       'priors_count', 'days_b_screening_arrest', \n",
    "       'decile_score', 'days_in_jail'] \n",
    "\n",
    "X_simulation = np.vstack([X_pos[col_X], X_neg[col_X]])\n",
    "X_simulation[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fSVecH66dgI",
    "outputId": "9c5a8fb1-041c-46a8-ca17-91bfb14c0cdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5122180451127819, 0.5309734513274337)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"evaluation metric 4: calibration\"\"\"\n",
    "\n",
    "calibration_pos = len(yhat_pos[((yhat_pos > 0.5) & (y_pos > 0.5)) |\n",
    "    ((yhat_pos <= 0.5) & (y_pos <= 0.5))])/len(yhat_pos)\n",
    "calibration_neg = len(yhat_neg[((yhat_neg > 0.5) & (y_neg > 0.5)) |\n",
    "    ((yhat_neg <= 0.5) & (y_neg <= 0.5))])/len(yhat_neg)\n",
    "calibration_pos, calibration_neg   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PEJtp6qSzHm"
   },
   "source": [
    "#eval 4: calibration\n",
    "The protected group is 51.2% calibrated, and the non protected group is 53.1% calibrated -- meaning the model is less likely to predict the protected group correctly but by a very small margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jX6F_C_j5_3D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
