{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bhAvqNYzb_X2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pickle\n",
        "import os\n",
        "import csv\n",
        "import scipy.optimize as optim\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LFR(self, X_s, X_ns, y_S, y_ns, k):\n",
        "  def __init__():\n",
        "    \"\"\"Here we will instantiate all of our parameters.\n",
        "    Learnable parameters: V (our prototype space), w (the weights associated with y_hat), and alpha (coefficients for distance)\n",
        "    non-learnable parameters: M_nk, M_k \"\"\"\n",
        "\n",
        "    #TODO: will need to initialize & fill in dimensions accordingly \n",
        "    P = X_s.shape[1]\n",
        "\n",
        "    #learnable parameters --> make sure to turn into torch.Parameters()!!\n",
        "    self.v = torch.nn.Parameter(torch.rand(k, P)) #kxP\n",
        "    self.w = torch.nn.Parameter(torch.rand(1, k)) #1xk\n",
        "    self.alpha = torch.nn.Parameter(torch.rand(1, 2*P)) #1xP\n",
        "\n",
        "    #unlearnable parameters\n",
        "    \n",
        "    #keep record of sensitive vs non-sensitive coefficients\n",
        "    self.alpha_S = self.alpha[:P]\n",
        "    self.alpha_nS = self.alpha[P:]\n",
        "\n",
        "    self.distances_S = self.distances(X_s, X_s.shape[0], P, k)\n",
        "    self.distances_nS = self.distances(X_ns, X_ns.shape[0], P, k)\n",
        "\n",
        "    self.M_nk_S = self.M_nk(distances_S, X_s.shape[0], k)\n",
        "    self.M_nk_nS = self.M_nk(distances_nS, X_ns.shape[0], k)\n",
        "\n",
        "    self.M_k_S = self.M_k(M_nk_S, X_s.shape[0], k)\n",
        "    self.M_k_nS = self.M_k(M_nk_nS, X_ns.shape[0], k)\n",
        "\n",
        "\n",
        "  def x_n_hat(X, M_nk, v, N, P, k):\n",
        "    x_n_hat = np.zeros((N, P))\n",
        "    L_x = 0.0\n",
        "    for i in range(N):\n",
        "        for p in range(P):\n",
        "            for j in range(k):\n",
        "                x_n_hat[i, p] += M_nk[i, j] * v[j, p]\n",
        "            L_x += (X[i, p] - x_n_hat[i, p]) * (X[i, p] - x_n_hat[i, p])\n",
        "    return x_n_hat, L_x\n",
        "  \n",
        "  def yhat(M_nk, y, w, N, k):\n",
        "    yhat = np.zeros(N)\n",
        "    L_y = 0.0\n",
        "    for i in range(N):\n",
        "        for j in range(k):\n",
        "            yhat[i] += M_nk[i, j] * w[j]\n",
        "        yhat[i] = 1e-6 if yhat[i] <= 0 else yhat[i]\n",
        "        yhat[i] = 0.999 if yhat[i] >= 1 else yhat[i]\n",
        "        L_y += -1 * y[i] * np.log(yhat[i]) - (1.0 - y[i]) * np.log(1.0 - yhat[i])\n",
        "    return yhat, L_y\n",
        "\n",
        "  def M_nk(self, dists, N, k):\n",
        "    M_nk = torch.zeros(N, k)\n",
        "    exp = torch.zeros(N, k)\n",
        "    denom = torch.zeros(N)\n",
        "    for i in range(N):\n",
        "        for j in range(k):\n",
        "            exp[i, j] = np.exp(-1 * dists[i, j])\n",
        "            denom[i] += exp[i, j]\n",
        "        for j in range(k):\n",
        "            if denom[i]:\n",
        "                M_nk[i, j] = exp[i, j] / denom[i]\n",
        "            else:\n",
        "                M_nk[i, j] = exp[i, j] / 1e-6\n",
        "    return M_nk\n",
        "   \n",
        "  def M_k(self, M_nk, N, k):\n",
        "    M_k = torch.zeros(k)\n",
        "    for j in range(k):\n",
        "        for i in range(N):\n",
        "            M_k[j] += M_nk[i, j]\n",
        "        M_k[j] /= N\n",
        "    return \n",
        "  \n",
        "  def recover_Z():\n",
        "    #TODO: fill in whatever we need to calculate LZ\n",
        "    pass\n",
        "\n",
        "  def forward(self,X,y):\n",
        "    #TODO: make sure this works accordingly! do we need to readjust our parameters? do we need to call self?\n",
        "    x_n_hat, L_x = x_n_hat(X, M_nk, v, N, P, k)\n",
        "    y_hat, L_y = yhat(M_nk, y, w, N, k)\n",
        "    Z = recover_Z()\n",
        "    return x_n_hat, L_x, y_hat, L_y, Z\n",
        "\n",
        "  def distances(self, X, N, P, k):\n",
        "    dists = torch.zeros(N, P)\n",
        "    for i in range(N):\n",
        "        for p in range(P):\n",
        "            for j in range(k):    \n",
        "                dists[i, j] += (X[i, p] - self.v[j, p]) * (X[i, p] - self.v[j, p]) * self.alpha[p]\n",
        "    return dists\n",
        "  \n",
        "  def loss_fn(self, X, y, x_n_hat, L_x, y_hat, L_y, Z):\n",
        "    #TODO: calculate L = Lx + Ly + Lz\n",
        "    L_z = 0.0\n",
        "    for j in range(k):\n",
        "        L_z += abs(M_k_sensitive[j] - M_k_nonsensitive[j])\n",
        "\n",
        "    x_n_hat_sensitive, L_x1 = x_n_hat(data_sensitive, M_nk_sensitive, v, Ns, P, k)\n",
        "    x_n_hat_nonsensitive, L_x2 = x_n_hat(data_nonsensitive, M_nk_nonsensitive, v, Nns, P, k)\n",
        "    L_x = L_x1 + L_x2\n",
        "\n",
        "    yhat_sensitive, L_y1 = yhat(M_nk_sensitive, y_sensitive, w, Ns, k)\n",
        "    yhat_nonsensitive, L_y2 = yhat(M_nk_nonsensitive, y_nonsensitive, w, Nns, k)\n",
        "    L_y = L_y1 + L_y2\n",
        "\n",
        "    criterion = A_x * L_x + A_y * L_y + A_z * L_z\n",
        "    return criterion\n",
        "  \n",
        "  def update_M_nk():\n",
        "    #TODO: update M_nk after SGD\n",
        "    pass\n",
        "  \n",
        "  def update_Mk():\n",
        "    #TODO: update M_k after SGD\n",
        "    pass\n",
        "\n",
        "  def update_distances():\n",
        "    #TODO: update distances\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "joL2QOlScSpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LFR()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        x_n_hat, L_x, y_hat, L_y, Z = model.forward(X)\n",
        "        loss = model.loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.update_Mnk()\n",
        "        model.update_Mk()\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "vzGAA2l1gBEK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}